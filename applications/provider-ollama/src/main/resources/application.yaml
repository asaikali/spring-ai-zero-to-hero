spring:
  application:
    name: ollama-provider
  profiles:
    active: # spy,pgvector,observation
  ai:
    ollama:
      base-url: "http://localhost:11434/"
      embedding:        
        model: mxbai-embed-large
      chat:
        model: llama3.1
        # model: llava
  threads:
    virtual:
      enabled: true
---
spring:
  config:
    activate:
      on-profile: spy
  ai:
    ollama:
      base-url: "http://localhost:7777/ollama"

---
spring:
  config:
    activate:
      on-profile: pgvector
  datasource:
    url: jdbc:postgresql://localhost:15432/ollama
    username: postgres
    password: password
  ai:
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimension: 1024
---
spring:
  config:
    activate:
      on-profile: observation
  ai:
    chat:
      client:
        observation:
          include-input: true
      observations:
        include-error-logging: true
    vector:
      store:
        observations:
          include-query-response: true
management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics, prometheus
  metrics:
    distribution.percentiles-histogram.http.server.requests: true
  observations:
    key-values:
      application: ollama-provider
  tracing:
    sampling:
      probability: 1.0
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans


  datasource:
    url: jdbc:postgresql://localhost:5432/postgres
    username: postgres
    password: password